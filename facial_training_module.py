"""
Module pour l'entra√Ænement facial automatique lors de l'ajout d'√©tudiants
Ce module g√®re la capture de photos et la g√©n√©ration d'encodages
"""

import cv2
import os
import face_recognition
import pickle
import time
import sys
from datetime import datetime
from camera_manager import CameraManager

class FacialTrainingModule:
    def __init__(self, dataset_folder="dataset", encodings_file="encodings.pickle"):
        """
        Initialise le module d'entra√Ænement facial
        
        Args:
            dataset_folder (str): Dossier contenant les images d'entra√Ænement
            encodings_file (str): Fichier contenant les encodages
        """
        self.dataset_folder = dataset_folder
        self.encodings_file = encodings_file
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
        
        # Cr√©er le dossier dataset s'il n'existe pas
        if not os.path.exists(self.dataset_folder):
            os.makedirs(self.dataset_folder)
            print(f"Dossier {self.dataset_folder} cr√©√©")

    def find_camera(self):
        """
        Trouve la meilleure cam√©ra disponible (priorit√© √† la cam√©ra int√©gr√©e)

        Returns:
            cv2.VideoCapture ou None: Objet cam√©ra ou None si aucune cam√©ra trouv√©e
        """
        print("üé• Recherche de la cam√©ra optimale pour l'entra√Ænement...")
        print("=" * 50)

        # Utiliser le gestionnaire de cam√©ras intelligent
        camera_manager = CameraManager()

        # D√©tecter toutes les cam√©ras disponibles
        cameras = camera_manager.detect_cameras()

        if not cameras:
            print("‚ùå Aucune cam√©ra d√©tect√©e")
            return None

        # Obtenir la meilleure cam√©ra (priorit√© √† la cam√©ra int√©gr√©e)
        cap = camera_manager.get_best_camera()

        if cap is not None:
            # Afficher les informations de la cam√©ra s√©lectionn√©e
            camera_info = camera_manager.get_camera_info()
            if camera_info:
                print(f"\n‚úÖ CAM√âRA S√âLECTIONN√âE POUR L'ENTRA√éNEMENT:")
                print(f"   üì∑ Nom: {camera_info['name']}")
                print(f"   üî¢ Index: {camera_info['index']}")
                print(f"   üñ•Ô∏è  Type: {'Cam√©ra int√©gr√©e' if camera_info['is_builtin'] else 'Cam√©ra externe'}")
                print(f"   üìê R√©solution: {camera_info['width']}x{camera_info['height']}")
                print("=" * 50)

            return cap
        else:
            print("‚ùå Impossible d'initialiser la cam√©ra s√©lectionn√©e")
            return None

    def capture_student_photos(self, prenom, nom, max_photos=15):
        """
        Capture des photos d'un √©tudiant pour l'entra√Ænement
        
        Args:
            prenom (str): Pr√©nom de l'√©tudiant
            nom (str): Nom de l'√©tudiant
            max_photos (int): Nombre maximum de photos √† capturer
            
        Returns:
            tuple: (bool, int) - (Succ√®s, nombre de photos captur√©es)
        """
        print(f"\n=== CAPTURE DE PHOTOS POUR {prenom} {nom} ===")
        
        # Normaliser le nom pour le fichier
        full_name = f"{prenom}_{nom}".replace(" ", "_")
        
        # Trouver une cam√©ra
        cap = self.find_camera()
        if cap is None:
            print("‚ùå Impossible de trouver une cam√©ra. Capture annul√©e.")
            return False, 0
        
        try:
            # Configurer la cam√©ra
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            
            count = 0
            last_capture_time = 0
            capture_interval = 1.0  # Intervalle minimum entre les captures (secondes)
            
            print(f"\nüì∏ INSTRUCTIONS DE CAPTURE:")
            print(f"‚Ä¢ Objectif: {max_photos} photos")
            print(f"‚Ä¢ Appuyez sur 'ESPACE' pour capturer une photo")
            print(f"‚Ä¢ Appuyez sur 'a' pour capture automatique")
            print(f"‚Ä¢ Appuyez sur 'q' pour terminer")
            print(f"‚Ä¢ Variez les angles et expressions pour de meilleurs r√©sultats")
            print(f"\nüéØ Positionnez votre visage dans le rectangle vert et commencez!")
            
            auto_capture = False
            
            while count < max_photos:
                ret, frame = cap.read()
                if not ret:
                    print("‚ùå Erreur lors de la lecture de la cam√©ra")
                    break
                
                # D√©tecter les visages
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)
                
                # Dessiner les rectangles autour des visages
                face_detected = len(faces) > 0
                for (x, y, w, h) in faces:
                    color = (0, 255, 0) if face_detected else (0, 0, 255)
                    cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
                    
                    # Ajouter du texte pour guider l'utilisateur
                    if face_detected:
                        cv2.putText(frame, "Visage detecte - Pret!", (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                # Afficher les informations √† l'√©cran
                cv2.putText(frame, f"Photos: {count}/{max_photos}", (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                
                cv2.putText(frame, f"Etudiant: {prenom} {nom}", (10, 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                if auto_capture:
                    cv2.putText(frame, "MODE AUTO - Capture en cours...", (10, 90),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                else:
                    cv2.putText(frame, "ESPACE: Capturer | A: Auto | Q: Quitter", (10, 90),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # Afficher le statut de d√©tection
                if not face_detected:
                    cv2.putText(frame, "Aucun visage detecte", (10, 120),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                
                cv2.imshow(f"Capture Photos - {prenom} {nom}", frame)
                
                # Gestion des touches
                key = cv2.waitKey(1) & 0xFF
                current_time = time.time()
                
                # Capture manuelle avec ESPACE
                if key == ord(' '):
                    if face_detected and current_time - last_capture_time > capture_interval:
                        success = self._save_photo(frame, faces[0], full_name, count + 1)
                        if success:
                            count += 1
                            last_capture_time = current_time
                            print(f"üì∏ Photo {count}/{max_photos} captur√©e")
                    elif not face_detected:
                        print("‚ö†Ô∏è  Aucun visage d√©tect√©. Repositionnez-vous.")
                    else:
                        print("‚ö†Ô∏è  Attendez un moment avant la prochaine capture.")
                
                # Mode automatique
                elif key == ord('a'):
                    auto_capture = not auto_capture
                    mode = "activ√©" if auto_capture else "d√©sactiv√©"
                    print(f"ü§ñ Mode automatique {mode}")
                
                # Capture automatique
                if auto_capture and face_detected and current_time - last_capture_time > capture_interval:
                    success = self._save_photo(frame, faces[0], full_name, count + 1)
                    if success:
                        count += 1
                        last_capture_time = current_time
                        print(f"üì∏ Photo {count}/{max_photos} captur√©e automatiquement")
                
                # Quitter
                if key == ord('q'):
                    print("üõë Capture interrompue par l'utilisateur")
                    break
            
            print(f"\n‚úÖ Capture termin√©e: {count} photos sauvegard√©es")
            return True, count
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la capture: {e}")
            return False, 0
            
        finally:
            cap.release()
            cv2.destroyAllWindows()

    def _save_photo(self, frame, face_coords, full_name, photo_number):
        """
        Sauvegarde une photo de visage
        
        Args:
            frame: Image compl√®te de la cam√©ra
            face_coords: Coordonn√©es du visage (x, y, w, h)
            full_name: Nom complet format√©
            photo_number: Num√©ro de la photo
            
        Returns:
            bool: Succ√®s de la sauvegarde
        """
        try:
            x, y, w, h = face_coords
            
            # Extraire le visage avec une marge
            margin = 20
            y_start = max(0, y - margin)
            y_end = min(frame.shape[0], y + h + margin)
            x_start = max(0, x - margin)
            x_end = min(frame.shape[1], x + w + margin)
            
            face = frame[y_start:y_end, x_start:x_end]
            
            # Redimensionner pour une taille standard
            face_resized = cv2.resize(face, (200, 200))
            
            # Sauvegarder
            filename = f"{self.dataset_folder}/{full_name}_{photo_number}.jpg"
            success = cv2.imwrite(filename, face_resized)
            
            if success:
                return True
            else:
                print(f"‚ùå Erreur lors de la sauvegarde de {filename}")
                return False
                
        except Exception as e:
            print(f"‚ùå Erreur lors de la sauvegarde de la photo: {e}")
            return False

    def generate_encodings(self):
        """
        G√©n√®re les encodages pour toutes les images du dataset
        
        Returns:
            bool: Succ√®s de la g√©n√©ration des encodages
        """
        print(f"\n=== G√âN√âRATION DES ENCODAGES ===")
        
        try:
            known_encodings = []
            known_names = []
            processed_files = 0
            skipped_files = 0
            
            # Parcourir toutes les images du dataset
            image_files = [f for f in os.listdir(self.dataset_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]
            
            if not image_files:
                print("‚ùå Aucune image trouv√©e dans le dataset")
                return False
            
            print(f"üìÅ Traitement de {len(image_files)} images...")
            
            for filename in image_files:
                img_path = os.path.join(self.dataset_folder, filename)
                
                try:
                    # Charger l'image
                    image = face_recognition.load_image_file(img_path)
                    encodings = face_recognition.face_encodings(image)
                    
                    if len(encodings) > 0:
                        encoding = encodings[0]
                        # Extraire le nom (format: Prenom_Nom_X.jpg)
                        name_parts = filename.split("_")
                        if len(name_parts) >= 2:
                            name = "_".join(name_parts[:2])  # Prenom_Nom
                        else:
                            name = filename.split(".")[0]  # Fallback
                        
                        known_encodings.append(encoding)
                        known_names.append(name)
                        processed_files += 1
                        print(f"‚úÖ {filename} -> {name}")
                    else:
                        skipped_files += 1
                        print(f"‚ö†Ô∏è  Aucun visage d√©tect√© dans {filename}")
                        
                except Exception as e:
                    skipped_files += 1
                    print(f"‚ùå Erreur avec {filename}: {e}")
            
            if processed_files == 0:
                print("‚ùå Aucun encodage g√©n√©r√©")
                return False
            
            # Sauvegarder les encodages
            data = {"encodings": known_encodings, "names": known_names}
            with open(self.encodings_file, "wb") as f:
                pickle.dump(data, f)
            
            print(f"\n‚úÖ Encodages sauvegard√©s dans {self.encodings_file}")
            print(f"üìä R√©sum√©: {processed_files} encodages g√©n√©r√©s, {skipped_files} fichiers ignor√©s")
            
            # Afficher les noms uniques
            unique_names = list(set(known_names))
            print(f"üë• Personnes enregistr√©es: {', '.join(unique_names)}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration des encodages: {e}")
            return False

    def train_student(self, prenom, nom, max_photos=15):
        """
        Processus complet d'entra√Ænement pour un √©tudiant
        
        Args:
            prenom (str): Pr√©nom de l'√©tudiant
            nom (str): Nom de l'√©tudiant
            max_photos (int): Nombre maximum de photos √† capturer
            
        Returns:
            bool: Succ√®s de l'entra√Ænement complet
        """
        print(f"\nüéì D√âBUT DE L'ENTRA√éNEMENT FACIAL POUR {prenom} {nom}")
        
        # √âtape 1: Capture des photos
        capture_success, photos_count = self.capture_student_photos(prenom, nom, max_photos)
        
        if not capture_success or photos_count == 0:
            print("‚ùå √âchec de la capture de photos")
            return False
        
        print(f"‚úÖ {photos_count} photos captur√©es avec succ√®s")
        
        # √âtape 2: G√©n√©ration des encodages
        encoding_success = self.generate_encodings()
        
        if not encoding_success:
            print("‚ùå √âchec de la g√©n√©ration des encodages")
            return False
        
        print(f"‚úÖ Encodages g√©n√©r√©s avec succ√®s")
        print(f"üéâ Entra√Ænement termin√© pour {prenom} {nom}!")
        print(f"üîç L'√©tudiant peut maintenant √™tre reconnu par le syst√®me")
        
        return True

# Fonction utilitaire pour tester le module
if __name__ == "__main__":
    trainer = FacialTrainingModule()
    
    # Test avec un √©tudiant fictif
    prenom = input("Pr√©nom de l'√©tudiant: ").strip()
    nom = input("Nom de l'√©tudiant: ").strip()
    
    if prenom and nom:
        success = trainer.train_student(prenom, nom)
        if success:
            print("üéâ Entra√Ænement r√©ussi!")
        else:
            print("‚ùå Entra√Ænement √©chou√©")
    else:
        print("‚ùå Nom ou pr√©nom manquant")
